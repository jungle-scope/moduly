"""
Database seed helpers for startup.

- Seeds a placeholder user for local/dev
- Seeds system LLM providers (idempotent)
"""

import logging
import uuid
from typing import Iterable

from apps.shared.db.models.llm import LLMProvider
from apps.shared.db.models.user import User
from sqlalchemy.orm import Session

PLACEHOLDER_USER_ID = uuid.UUID("12345678-1234-5678-1234-567812345678")

logger = logging.getLogger(__name__)


def seed_placeholder_user(db: Session) -> None:
    """Ensure the dev placeholder user exists."""
    user = db.query(User).filter(User.id == PLACEHOLDER_USER_ID).first()
    if user:
        return

    from services.auth_service import AuthService

    dev_user = User(
        id=PLACEHOLDER_USER_ID,
        email="dev@moduly.app",
        name="Dev User",
        password=AuthService.hash_password("dev-password"),
        social_provider="none",
    )
    db.add(dev_user)
    db.commit()
    logger.info(
        "âœ… ê¸°ë³¸ userìœ ì € (id: dev@moduly.app / password: dev-password ) ìƒì„±ì™„ë£Œ!"
    )


def _default_providers() -> Iterable[LLMProvider]:
    """Return the default LLM provider rows to seed."""
    return [
        LLMProvider(
            name="openai",
            description="OpenAI default provider",
            base_url="https://api.openai.com/v1",
            type="system",
            auth_type="api_key",
            doc_url="https://platform.openai.com/api-keys",
        ),
        LLMProvider(
            name="anthropic",
            description="Anthropic Claude provider",
            base_url="https://api.anthropic.com/v1",
            type="system",
            auth_type="api_key",
            doc_url="https://console.anthropic.com/settings/keys",
        ),
        LLMProvider(
            name="google",
            description="Google Gemini provider",
            base_url="https://generativelanguage.googleapis.com/v1beta/openai",
            type="system",
            auth_type="api_key",
            doc_url="https://aistudio.google.com/",
        ),
        LLMProvider(
            name="llamaparse",
            description="LlamaParse high-quality document parser (LlamaIndex Cloud)",
            base_url="https://api.cloud.llamaindex.ai",
            type="system",
            auth_type="api_key",
            doc_url="https://cloud.llamaindex.ai/api-key",
        ),
    ]


def seed_default_llm_providers(db: Session) -> None:
    """Insert default providers if missing; idempotent per name."""
    existing_providers = db.query(LLMProvider).all()
    existing_names = {p.name for p in existing_providers}

    providers_to_add = [p for p in _default_providers() if p.name not in existing_names]
    if not providers_to_add:
        logger.warning(
            f"â„¹ï¸ LLM providers already exist ({len(existing_providers)}). Skipping seed."
        )
        return

    db.add_all(providers_to_add)
    db.commit()
    logger.info("âœ… Default LLM providers seeded!")


def seed_default_llm_models(db: Session) -> None:
    """
    KNOWN_MODEL_PRICESë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¸°ë³¸ LLM ëª¨ë¸ì„ ì‹œë“œí•©ë‹ˆë‹¤.
    gpt-4.1, o3-miniì™€ ê°™ì€ ëª¨ë¸ì´ DBì— ì¡´ì¬í•˜ë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤.
    ë˜í•œ, í•´ë‹¹ ëª¨ë¸ì´ UIì— í‘œì‹œë˜ë„ë¡ ê¸°ì¡´ Credentialê³¼ ì—°ê²°í•©ë‹ˆë‹¤.
    """
    from apps.gateway.services.llm_service import LLMService
    from apps.shared.db.models.llm import (
        LLMCredential,
        LLMModel,
        LLMProvider,
        LLMRelCredentialModel,
    )

    # 1. ëª¨ë“  Provider ì¡°íšŒ í›„ ë§µí•‘ ìƒì„±
    providers = db.query(LLMProvider).all()
    provider_map = {p.name: p for p in providers}

    # 2. ê¸°ì¡´ ìƒì„±ëœ ëª¨ë¸ ì¡°íšŒ
    existing_models = db.query(LLMModel).all()
    existing_model_ids = {m.model_id_for_api_call for m in existing_models}

    # Provider ë§¤í•‘ ê·œì¹™ (íœ´ë¦¬ìŠ¤í‹±)
    def get_provider_name(model_id: str) -> str:
        if model_id.startswith("claude"):
            return "anthropic"
        elif model_id.startswith("gemini"):
            return "google"
        elif model_id.startswith("llamaparse"):
            return "llamaparse"
        else:
            return "openai"  # gpt, o1, o3, dall-e, tts, whisper ë“±ì€ ê¸°ë³¸ì ìœ¼ë¡œ OpenAIë¡œ ì²˜ë¦¬

    models_seeded_count = 0
    models_updated_count = 0

    # 3. KNOWN_MODEL_PRICES ìˆœíšŒí•˜ë©° ëª¨ë¸ ìƒì„± ë˜ëŠ” ê°€ê²© ì—…ë°ì´íŠ¸
    for model_id, pricing in LLMService.KNOWN_MODEL_PRICES.items():
        provider_name = get_provider_name(model_id)
        provider = provider_map.get(provider_name)

        if not provider:
            continue

        # ëª¨ë¸ ì°¾ê¸° ë˜ëŠ” ìƒì„±
        model = None
        if model_id in existing_model_ids:
            # ê¸°ì¡´ ëª¨ë¸ ê°ì²´ ì°¾ê¸°
            model = next(
                (m for m in existing_models if m.model_id_for_api_call == model_id),
                None,
            )
            # [NEW] ê¸°ì¡´ ëª¨ë¸ì´ì§€ë§Œ ê°€ê²© ì •ë³´ê°€ ì—†ìœ¼ë©´ ì—…ë°ì´íŠ¸
            if model and (
                model.input_price_1k is None or model.output_price_1k is None
            ):
                model.input_price_1k = pricing["input"]
                model.output_price_1k = pricing["output"]
                db.add(model)
                models_updated_count += 1
        else:
            # ìƒˆ ëª¨ë¸ ìƒì„±
            new_model_uuid = uuid.uuid4()
            model = LLMModel(
                id=new_model_uuid,
                provider_id=provider.id,
                model_id_for_api_call=model_id,
                name=model_id,
                type="embedding" if "embedding" in model_id else "chat",
                context_window=128000
                if "gpt-4" in model_id or "o1" in model_id or "claude" in model_id
                else 8192,
                input_price_1k=pricing["input"],
                output_price_1k=pricing["output"],
                is_active=True,
            )
            db.add(model)
            models_seeded_count += 1
            # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ìºì‹œ ì—…ë°ì´íŠ¸
            existing_model_ids.add(model_id)
            existing_models.append(model)

        if not model:
            continue

        # Providerì˜ ê¸°ì¡´ Credentialì— ì—°ê²° (ì„ íƒì‚¬í•­ - ì¡°íšŒ ë¡œì§ ë³€ê²½ìœ¼ë¡œ ì¸í•´ í•„ìˆ˜ëŠ” ì•„ë‹ˆì§€ë§Œ ì•ˆì „ì¥ì¹˜ë¡œ ìœ ì§€)
        # 1. í•´ë‹¹ Providerì˜ ëª¨ë“  Credential ì¡°íšŒ
        creds = (
            db.query(LLMCredential)
            .filter(LLMCredential.provider_id == provider.id)
            .all()
        )

        # 2. ì´ë¯¸ ì—°ê²°ëœ ë‚´ì—­ í™•ì¸
        existing_links = (
            db.query(LLMRelCredentialModel)
            .filter(LLMRelCredentialModel.model_id == model.id)
            .all()
        )
        linked_cred_ids = {link.credential_id for link in existing_links}

        # 3. ëˆ„ë½ëœ ì—°ê²° ì¶”ê°€
        for cred in creds:
            if cred.id not in linked_cred_ids:
                rel = LLMRelCredentialModel(
                    credential_id=cred.id, model_id=model.id, is_verified=True
                )
                db.add(rel)

    if models_seeded_count > 0 or models_updated_count > 0:
        if models_seeded_count > 0:
            logger.info(f"ğŸŒ± Seeded {models_seeded_count} new LLM models.")
        if models_updated_count > 0:
            logger.info(
                f"ğŸ’° Updated pricing for {models_updated_count} existing models."
            )
        db.commit()
        logger.info("âœ… LLM models sync complete!")
    else:
        logger.warning("â„¹ï¸ LLM models up to date.")
