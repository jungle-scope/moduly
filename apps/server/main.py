# .env íŒŒì¼ì„ ê¸°ë³¸ê°’ìœ¼ë¡œ ë¡œë“œ (ê°œë°œ í™˜ê²½)
from pathlib import Path

from dotenv import load_dotenv

BASE_DIR = Path(__file__).resolve().parent

# apps/server/.env ë¡œë“œ
SERVER_ENV_PATH = BASE_DIR / ".env"
if SERVER_ENV_PATH.exists():
    print(f"Loading .env from {SERVER_ENV_PATH}")
    load_dotenv(dotenv_path=SERVER_ENV_PATH)

import os
from contextlib import asynccontextmanager

from fastapi import FastAPI
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from sqlalchemy import text
from starlette.middleware.sessions import SessionMiddleware

from api.api import api_router
from db.base import Base
from db.models.schedule import Schedule  # noqa: F401
from db.seed import (
    seed_default_llm_models,
    seed_default_llm_providers,
    seed_placeholder_user,
)
from db.session import engine


@asynccontextmanager
async def lifespan(app: FastAPI):
    # 1. Startup Logic

    # pgvector í™•ì¥ í™œì„±í™”
    with engine.begin() as conn:
        conn.execute(text("CREATE EXTENSION IF NOT EXISTS vector"))

    Base.metadata.create_all(bind=engine)
    print("âœ… Database tables created successfully!")

    # 2. Seed Default LLM Providers (Idempotent)

    from db.session import SessionLocal

    db = SessionLocal()
    try:
        # 2.1 Seed Placeholder User (Critical for Dev)
        seed_placeholder_user(db)

        # 2.2 Seed Providers
        seed_default_llm_providers(db)

        # 2.3 ê¸°ë³¸ ëª¨ë¸ ì‹œë“œ (ì‹ ê·œ)
        seed_default_llm_models(db)

        # 2.4 ê¸°ì¡´ ëª¨ë¸ ê°€ê²© ë™ê¸°í™” (KNOWN_MODEL_PRICES ê¸°ë°˜)
        from services.llm_service import LLMService

        result = LLMService.sync_system_prices(db)
        if result["updated_models"] > 0:
            print(f"ğŸ’° Updated pricing for {result['updated_models']} existing models.")

        # 2.5 Initialize SchedulerService (ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘)
        from services.scheduler_service import init_scheduler_service

        print("ğŸ• SchedulerService ì´ˆê¸°í™” ì¤‘...")
        init_scheduler_service(db)
        print("âœ… SchedulerService ì´ˆê¸°í™” ì™„ë£Œ!")

    except Exception as e:
        print(f"âš ï¸ Failed to seed data: {e}")
        import traceback

        traceback.print_exc()
    finally:
        db.close()

    yield

    # Shutdown: SchedulerService ì¢…ë£Œ
    from services.scheduler_service import get_scheduler_service

    try:
        scheduler = get_scheduler_service()
        scheduler.shutdown()
    except Exception as e:
        print(f"âš ï¸ SchedulerService ì¢…ë£Œ ì‹¤íŒ¨: {e}")


app = FastAPI(title="Moduly API", lifespan=lifespan)

origins_str = os.getenv("CORS_ORIGINS", "http://localhost:3000,http://127.0.0.1:3000")
origins = origins_str.split(",")

# CORS ì„¤ì • (withCredentials ì§€ì›)
app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,  # .envì—ì„œ CORS_ORIGINSë¡œ ì„¤ì • ê°€ëŠ¥
    allow_credentials=True,  # ì¿ í‚¤ ì „ì†¡ í—ˆìš©
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì„¸ì…˜ ë¯¸ë“¤ì›¨ì–´ ì¶”ê°€ (OAuth ìƒíƒœ ì €ì¥ìš©)

app.add_middleware(
    SessionMiddleware,
    secret_key=os.getenv("SECRET_KEY", "your-secret-key-change-in-production"),
    https_only=os.getenv("NODE_ENV") == "production",  # ë°°í¬ í™˜ê²½ì—ì„œëŠ” Secure ì¿ í‚¤
)

# ì •ì  íŒŒì¼ ì„œë¹™ (widget.js)
app.mount("/static", StaticFiles(directory="static"), name="static")

# API ë¼ìš°í„° ë“±ë¡
app.include_router(api_router, prefix="/api/v1")


@app.get("/")
def root():
    return {"status": "ok"}
