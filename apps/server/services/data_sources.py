import os
from abc import ABC, abstractmethod
from typing import Any, Dict, List

import fitz  # PyMuPDF
import httpx
import pandas as pd
from docx import Document as DocxDocument
from llama_parse import LlamaParse


class BaseDataSource(ABC):
    @abstractmethod
    def fetch_text(self, source_config: Dict[str, Any]) -> List[dict]:
        """
        ì†ŒìŠ¤ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.

        Args:
            source_config:
            - FILEì˜ ê²½ìš°: {'file_path': '...', 'document_id': '...'}
            - APIì˜ ê²½ìš°: {'url': '...', 'method': '...', 'headers': '...', 'body': '...'}

        Returns:
            List[dict]: [{'text': '...', 'page': 1, ...}, ...]
        """
        pass

    @abstractmethod
    def estimate_cost(self, source_config: Dict[str, Any]) -> Dict[str, Any]:
        """
        ì˜ˆìƒ ë¹„ìš©ì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        Returns:
            {'pages': int, 'credits': int, 'cost_usd': float, 'recommended_strategy': str}
        """
        pass


class FileDataSource(BaseDataSource):
    def fetch_text(self, source_config: Dict[str, Any]) -> List[dict]:
        file_path = source_config.get("file_path")
        if not file_path or not os.path.exists(file_path):
            raise FileNotFoundError(f"File not found: {file_path}")

        ext = os.path.splitext(file_path)[1].lower()
        strategy = source_config.get("strategy", "auto")

        if ext == ".pdf":
            return self._parse_pdf(file_path, strategy)
        elif ext in [".xlsx", ".xls", ".csv"]:
            return self._parse_excel_csv(file_path)
        elif ext == ".docx":
            return self._parse_docx(file_path)
        elif ext in [".txt", ".md"]:
            return self._parse_txt(file_path)
        else:
            print(f"[Warning] Unsupported file type: {ext}. Trying as text.")
            return self._parse_txt(file_path)

    def estimate_cost(self, source_config: Dict[str, Any]) -> Dict[str, Any]:
        file_path = source_config.get("file_path")
        if not file_path or not os.path.exists(file_path):
            return {
                "pages": 0,
                "credits": 0,
                "cost_usd": 0.0,
                "recommended_strategy": "general",
            }

        try:
            # PDFê°€ ì•„ë‹Œ ê²½ìš° fitz.open()ì´ ì‹¤íŒ¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì˜ˆì™¸ ì²˜ë¦¬
            ext = os.path.splitext(file_path)[1].lower()
            if ext not in [".pdf", ".xps", ".epub", ".mobi", ".fb2", ".cbz", ".svg"]:
                return {
                    "pages": 0,
                    "credits": 0,
                    "cost_usd": 0.0,
                    "recommended_strategy": "general",
                }

            doc = fitz.open(file_path)
            total_pages = len(doc)
            doc.close()

            # Standard Mode ê¸°ì¤€ (í˜ì´ì§€ë‹¹ 3 í¬ë ˆë”§)
            credits_per_page = 3
            total_credits = total_pages * credits_per_page
            cost_usd = total_credits / 1000.0

            return {
                "pages": total_pages,
                "credits": total_credits,
                "cost_usd": cost_usd,
                "recommended_strategy": "llamaparse" if total_pages > 0 else "general",
            }
        except Exception as e:
            print(f"[Warning] Cost estimation failed: {e}")
            return {
                "pages": 0,
                "credits": 0,
                "cost_usd": 0.0,
                "recommended_strategy": "general",
            }

    def _parse_pdf(self, file_path: str, strategy: str = "auto") -> List[dict]:
        """PDF íŒŒì‹± (ê¸°ì¡´ ë¡œì§ ì´ê´€)"""
        text_blocks = []
        try:
            # 1. Force LlamaParse strategy
            if strategy == "llamaparse":
                return self._parse_with_llamaparse(file_path)

            # 2. General / Auto strategy (Try PyMuPDF first)
            doc = fitz.open(file_path)
            is_scanned = True
            for page_num, page in enumerate(doc):
                text = page.get_text()
                if text.strip():
                    is_scanned = False
                    text_blocks.append({"text": text, "page": page_num + 1})
            doc.close()

            # 3. If 'auto' and scanned/empty, fallback to LlamaParse
            if strategy == "auto" and (is_scanned or not text_blocks):
                print("ğŸ“„ ìŠ¤ìº”ëœ PDF ë˜ëŠ” ì´ë¯¸ì§€ë¡œ ê°ì§€ë¨. LlamaParseë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                return self._parse_with_llamaparse(file_path)

            return text_blocks
        except Exception as e:
            print(f"PDF parsing failed: {e}")
            return []

    def _parse_with_llamaparse(self, file_path: str) -> List[dict]:
        """LlamaParse ì—°ë™ (ìºì‹± ì§€ì›)"""

        cache_path = f"{file_path}.md"

        # ìºì‹œ í™•ì¸
        if os.path.exists(cache_path):
            print(f"ğŸ“¦ Found cached LlamaParse result: {cache_path}")
            try:
                with open(cache_path, "r", encoding="utf-8") as f:
                    md_text = f.read()
                # ìºì‹œëœ íŒŒì¼ì€ í˜ì´ì§€ ì •ë³´ê°€ í•©ì³ì ¸ ìˆìœ¼ë¯€ë¡œ í•˜ë‚˜ì˜ ë¸”ë¡ìœ¼ë¡œ ë°˜í™˜
                return [{"text": md_text, "page": 1}]
            except Exception as e:
                print(f"Failed to read cache: {e}")
                # ì½ê¸° ì‹¤íŒ¨ ì‹œ ì¬íŒŒì‹± ì‹œë„

        try:
            api_key = os.getenv("LLAMA_CLOUD_API_KEY")
            if not api_key:
                print("âŒ LLAMA_CLOUD_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return []

            parser = LlamaParse(
                api_key=api_key,
                result_type="markdown",
                verbose=True,
                language="ko",
                fast_mode=True,
            )

            json_results = parser.get_json_result(file_path)
            parsed_results = []
            full_md_text = ""

            if json_results and isinstance(json_results, list):
                first_result = json_results[0]
                pages = first_result.get("pages", [])
                for p in pages:
                    md_text = p.get("md") or p.get("text") or ""
                    parsed_results.append(
                        {
                            "text": md_text,
                            "page": p["page"],
                        }
                    )
                    full_md_text += md_text + "\n\n"

            # ìºì‹œ ì €ì¥
            if full_md_text:
                try:
                    with open(cache_path, "w", encoding="utf-8") as f:
                        f.write(full_md_text)
                    print(f"ğŸ’¾ Caved LlamaParse result to: {cache_path}")
                except Exception as e:
                    print(f"Failed to write cache: {e}")

            return parsed_results
        except ImportError:
            print("âŒ LlamaParse ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        except Exception as e:
            print(f"LlamaParse ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return []

    def _parse_excel_csv(self, file_path: str) -> List[dict]:
        """Excel/CSV íŒŒì‹±"""
        text_content = ""
        ext = os.path.splitext(file_path)[1].lower()
        try:
            if ext == ".csv":
                df = pd.read_csv(file_path)
                text_content += f"# CSV Content\n\n{df.to_markdown(index=False)}\n"
            else:
                xls = pd.read_excel(file_path, sheet_name=None)
                for sheet_name, df in xls.items():
                    text_content += f"\n# Sheet: {sheet_name}\n\n"
                    text_content += df.to_markdown(index=False) + "\n"
            return [{"text": text_content, "page": 1}]
        except Exception as e:
            print(f"Excel/CSV parsing failed: {e}")
            return []

    def _parse_docx(self, file_path: str) -> List[dict]:
        """Word íŒŒì‹±"""
        try:
            doc = DocxDocument(file_path)
            full_text = []
            for para in doc.paragraphs:
                if para.text.strip():
                    full_text.append(para.text)
            return [{"text": "\n".join(full_text), "page": 1}]
        except Exception as e:
            print(f"DOCX parsing failed: {e}")
            return []

    def _parse_txt(self, file_path: str) -> List[dict]:
        """Text íŒŒì‹±"""
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                return [{"text": f.read(), "page": 1}]
        except Exception as e:
            print(f"TXT parsing failed: {e}")
            return []


class ApiDataSource(BaseDataSource):
    def fetch_text(self, source_config: Dict[str, Any]) -> List[dict]:
        """
        REST APIì—ì„œ ë°ì´í„° ì¶”ì¶œ
        source_config: {
            "url": "...",
            "method": "GET",
            "headers": {...},
            "body": {...},
            "field_mapping": "response.data" # ì  í‘œê¸°ë²•ìœ¼ë¡œ í…ìŠ¤íŠ¸ ìœ„ì¹˜ ì§€ì •
        }
        """
        url = source_config.get("url")
        if not url:
            raise ValueError("URL is required for API source")

        method = source_config.get("method", "GET").upper()
        headers = source_config.get("headers", {})
        body = source_config.get("body")

        try:
            with httpx.Client(timeout=60.0) as client:
                response = client.request(method, url, headers=headers, json=body)
                response.raise_for_status()

                data = response.json()

                # TODO: field_mappingì„ ì‚¬ìš©í•˜ì—¬ íŠ¹ì • í•„ë“œë§Œ ì¶”ì¶œí•˜ëŠ” ë¡œì§ í•„ìš”
                # í˜„ì¬ëŠ” ì „ì²´ JSONì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                import json

                text_content = json.dumps(data, ensure_ascii=False, indent=2)

                return [{"text": text_content, "page": 1}]

        except Exception as e:
            print(f"API fetch failed: {e}")
            raise e

    def estimate_cost(self, source_config: Dict[str, Any]) -> Dict[str, Any]:
        # API ì†ŒìŠ¤ëŠ” í˜„ì¬ ë¹„ìš© ì˜ˆì¸¡ ë¡œì§ ì—†ìŒ (ë¬´ë£Œë¡œ ê°€ì •)
        return {
            "pages": 0,
            "credits": 0,
            "cost_usd": 0.0,
            "recommended_strategy": "general",
        }
