"""
Database seed helpers for startup.

- Seeds a placeholder user for local/dev
- Seeds system LLM providers (idempotent)
"""

import uuid
from typing import Iterable

from sqlalchemy.orm import Session

from shared.db.models.llm import LLMProvider
from shared.db.models.user import User


PLACEHOLDER_USER_ID = uuid.UUID("12345678-1234-5678-1234-567812345678")


def seed_placeholder_user(db: Session) -> None:
    """Ensure the dev placeholder user exists."""
    user = db.query(User).filter(User.id == PLACEHOLDER_USER_ID).first()
    if user:
        return

    dev_user = User(
        id=PLACEHOLDER_USER_ID,
        email="dev@moduly.app",
        name="Dev User",
        password="dev-password",
    )
    db.add(dev_user)
    db.commit()
    print("âœ… Placeholder user created!")


def _default_providers() -> Iterable[LLMProvider]:
    """Return the default LLM provider rows to seed."""
    return [
        LLMProvider(
            name="openai",
            description="OpenAI default provider",
            base_url="https://api.openai.com/v1",
            type="system",
            auth_type="api_key",
            doc_url="https://platform.openai.com/api-keys",
        ),
        LLMProvider(
            name="anthropic",
            description="Anthropic Claude provider",
            base_url="https://api.anthropic.com/v1",
            type="system",
            auth_type="api_key",
            doc_url="https://console.anthropic.com/settings/keys",
        ),
        LLMProvider(
            name="google",
            description="Google Gemini provider",
            base_url="https://generativelanguage.googleapis.com/v1beta/openai",
            type="system",
            auth_type="api_key",
            doc_url="https://aistudio.google.com/",
        ),
        LLMProvider(
            name="llamaparse",
            description="LlamaParse high-quality document parser (LlamaIndex Cloud)",
            base_url="https://api.cloud.llamaindex.ai",
            type="system",
            auth_type="api_key",
            doc_url="https://cloud.llamaindex.ai/api-key",
        ),
    ]


def seed_default_llm_providers(db: Session) -> None:
    """Insert default providers if missing; idempotent per name."""
    existing_providers = db.query(LLMProvider).all()
    existing_names = {p.name for p in existing_providers}

    providers_to_add = [p for p in _default_providers() if p.name not in existing_names]
    if not providers_to_add:
        print(f"â„¹ï¸ LLM providers already exist ({len(existing_providers)}). Skipping seed.")
        return

    print(f"ğŸŒ± Seeding default LLM providers ({len(providers_to_add)} new)...")
    db.add_all(providers_to_add)
    db.commit()
    print("âœ… Default LLM providers seeded!")


def seed_default_llm_models(db: Session) -> None:
    """
    KNOWN_MODEL_PRICESë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê¸°ë³¸ LLM ëª¨ë¸ì„ ì‹œë“œí•©ë‹ˆë‹¤.
    gpt-4.1, o3-miniì™€ ê°™ì€ ëª¨ë¸ì´ DBì— ì¡´ì¬í•˜ë„ë¡ ë³´ì¥í•©ë‹ˆë‹¤.
    ë˜í•œ, í•´ë‹¹ ëª¨ë¸ì´ UIì— í‘œì‹œë˜ë„ë¡ ê¸°ì¡´ Credentialê³¼ ì—°ê²°í•©ë‹ˆë‹¤.
    """
    from services.llm_service import LLMService
    from shared.db.models.llm import LLMProvider, LLMModel, LLMCredential, LLMRelCredentialModel

    # 1. ëª¨ë“  Provider ì¡°íšŒ í›„ ë§µí•‘ ìƒì„±
    providers = db.query(LLMProvider).all()
    provider_map = {p.name: p for p in providers}

    # 2. ê¸°ì¡´ ìƒì„±ëœ ëª¨ë¸ ì¡°íšŒ
    existing_models = db.query(LLMModel).all()
    existing_model_ids = {m.model_id_for_api_call for m in existing_models}

    # Provider ë§¤í•‘ ê·œì¹™ (íœ´ë¦¬ìŠ¤í‹±)
    def get_provider_name(model_id: str) -> str:
        if model_id.startswith("claude"):
            return "anthropic"
        elif model_id.startswith("gemini"):
            return "google"
        elif model_id.startswith("llamaparse"):
            return "llamaparse"
        else:
            return "openai" # gpt, o1, o3, dall-e, tts, whisper ë“±ì€ ê¸°ë³¸ì ìœ¼ë¡œ OpenAIë¡œ ì²˜ë¦¬

    models_seeded_count = 0
    models_updated_count = 0

    # 3. KNOWN_MODEL_PRICES ìˆœíšŒí•˜ë©° ëª¨ë¸ ìƒì„± ë˜ëŠ” ê°€ê²© ì—…ë°ì´íŠ¸
    for model_id, pricing in LLMService.KNOWN_MODEL_PRICES.items():
        provider_name = get_provider_name(model_id)
        provider = provider_map.get(provider_name)
        
        if not provider:
            # print(f"âš ï¸ Provider '{provider_name}' not found for model '{model_id}'. Skipping.")
            continue
            
        # ëª¨ë¸ ì°¾ê¸° ë˜ëŠ” ìƒì„±
        model = None
        if model_id in existing_model_ids:
            # ê¸°ì¡´ ëª¨ë¸ ê°ì²´ ì°¾ê¸°
            model = next((m for m in existing_models if m.model_id_for_api_call == model_id), None)
            # [NEW] ê¸°ì¡´ ëª¨ë¸ì´ì§€ë§Œ ê°€ê²© ì •ë³´ê°€ ì—†ìœ¼ë©´ ì—…ë°ì´íŠ¸
            if model and (model.input_price_1k is None or model.output_price_1k is None):
                model.input_price_1k = pricing["input"]
                model.output_price_1k = pricing["output"]
                db.add(model)
                models_updated_count += 1
        else:
            # ìƒˆ ëª¨ë¸ ìƒì„±
            new_model_uuid = uuid.uuid4()
            model = LLMModel(
                id=new_model_uuid,
                provider_id=provider.id,
                model_id_for_api_call=model_id,
                name=model_id, 
                type="embedding" if "embedding" in model_id else "chat",
                context_window=128000 if "gpt-4" in model_id or "o1" in model_id or "claude" in model_id else 8192,
                input_price_1k=pricing["input"],
                output_price_1k=pricing["output"],
                is_active=True
            )
            db.add(model)
            models_seeded_count += 1
            # ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ìºì‹œ ì—…ë°ì´íŠ¸
            existing_model_ids.add(model_id)
            existing_models.append(model)
        
        if not model: continue

        # Providerì˜ ê¸°ì¡´ Credentialì— ì—°ê²° (ì„ íƒì‚¬í•­ - ì¡°íšŒ ë¡œì§ ë³€ê²½ìœ¼ë¡œ ì¸í•´ í•„ìˆ˜ëŠ” ì•„ë‹ˆì§€ë§Œ ì•ˆì „ì¥ì¹˜ë¡œ ìœ ì§€)
        # 1. í•´ë‹¹ Providerì˜ ëª¨ë“  Credential ì¡°íšŒ
        creds = db.query(LLMCredential).filter(LLMCredential.provider_id == provider.id).all()
        
        # 2. ì´ë¯¸ ì—°ê²°ëœ ë‚´ì—­ í™•ì¸
        existing_links = db.query(LLMRelCredentialModel).filter(
            LLMRelCredentialModel.model_id == model.id
        ).all()
        linked_cred_ids = {link.credential_id for link in existing_links}
        
        # 3. ëˆ„ë½ëœ ì—°ê²° ì¶”ê°€
        for cred in creds:
             if cred.id not in linked_cred_ids:
                 rel = LLMRelCredentialModel(
                     credential_id=cred.id,
                     model_id=model.id,
                     is_verified=True
                 )
                 db.add(rel)
                 # print(f"   Configs: Linked {model_id} to Credential {cred.credential_name}")

    if models_seeded_count > 0 or models_updated_count > 0:
        if models_seeded_count > 0:
            print(f"ğŸŒ± Seeded {models_seeded_count} new LLM models.")
        if models_updated_count > 0:
            print(f"ğŸ’° Updated pricing for {models_updated_count} existing models.")
        db.commit()
        print("âœ… LLM models sync complete!")
    else:
        print("â„¹ï¸ LLM models up to date.")
